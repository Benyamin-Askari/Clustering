{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benyamin-Askari/Clustering/blob/main/Wearable%2C_EDA%2C_Preprocessing%2C_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup and Library Installation\n",
        "python\n",
        "Copy code\n"
      ],
      "metadata": {
        "id": "QZitvi7MJP5A"
      },
      "id": "QZitvi7MJP5A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs necessary Python libraries, including pandas for data manipulation, numpy for numerical computations, matplotlib and seaborn for visualization, and missingno for analyzing missing data."
      ],
      "metadata": {
        "id": "hh3F6949JmFi"
      },
      "id": "hh3F6949JmFi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "085d16d7-8171-40d2-8484-8fc7022814de",
      "metadata": {
        "id": "085d16d7-8171-40d2-8484-8fc7022814de"
      },
      "outputs": [],
      "source": [
        "!pip install pandas numpy matplotlib seaborn missingno"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries and Loading the Dataset"
      ],
      "metadata": {
        "id": "1gRLOF9HJ2GE"
      },
      "id": "1gRLOF9HJ2GE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reads a CSV file containing the dataset into a pandas DataFrame."
      ],
      "metadata": {
        "id": "BQnKcimLJ71Z"
      },
      "id": "BQnKcimLJ71Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca199f44-206a-4fb2-aa6b-bc2fe618ed6c",
      "metadata": {
        "id": "ca199f44-206a-4fb2-aa6b-bc2fe618ed6c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load the dataset\n",
        "data = pd.read_csv('filtered_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Overview"
      ],
      "metadata": {
        "id": "ImKc5ilNJ_BG"
      },
      "id": "ImKc5ilNJ_BG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displays the dataset's shape, summary statistics, and the first few rows to understand its structure."
      ],
      "metadata": {
        "id": "dSxX-vB4KE5A"
      },
      "id": "dSxX-vB4KE5A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74a554aa-323c-45d0-bf3f-3199d358bc89",
      "metadata": {
        "id": "74a554aa-323c-45d0-bf3f-3199d358bc89",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "## Overview of the dataset\n",
        "print(\"Dataset Shape:\", data.shape)\n",
        "data.info()\n",
        "print(data.describe(include='all'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "100d7de8-ea40-4e8f-9032-51e4007cbf33",
      "metadata": {
        "id": "100d7de8-ea40-4e8f-9032-51e4007cbf33"
      },
      "outputs": [],
      "source": [
        "## Display the first few rows\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizations\n",
        "Pairwise Scatter for numerical columns (excluding Subject ID and Activity_Label)."
      ],
      "metadata": {
        "id": "I9qfxKDFKRGk"
      },
      "id": "I9qfxKDFKRGk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "812d1ef5-82bb-4eb2-ab4f-5dd338beaf70",
      "metadata": {
        "id": "812d1ef5-82bb-4eb2-ab4f-5dd338beaf70"
      },
      "outputs": [],
      "source": [
        "## Pairwise scatter plot matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "sns.pairplot(data.drop(columns=['Subject ID', 'Activity_Label']).dropna(), diag_kind='kde', plot_kws={'alpha': 0.5})\n",
        "plt.suptitle('Pairwise Scatter Plot Matrix', y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histograms for numerical columns to visualize distributions"
      ],
      "metadata": {
        "id": "6-jA63SXKpmr"
      },
      "id": "6-jA63SXKpmr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f30b6db-e124-4731-81ab-e95073cd8621",
      "metadata": {
        "id": "3f30b6db-e124-4731-81ab-e95073cd8621"
      },
      "outputs": [],
      "source": [
        "# Columns to exclude from plotting\n",
        "exclude_cols = ['Subject ID', 'Activity_Label']\n",
        "\n",
        "# Select numerical columns excluding the specified columns\n",
        "import numpy as np\n",
        "\n",
        "numerical_cols = data.select_dtypes(include=['number']).columns.tolist()\n",
        "numerical_cols = [col for col in numerical_cols if col not in exclude_cols]\n",
        "\n",
        "# Set the style for seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot Histograms\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for idx, col in enumerate(numerical_cols):\n",
        "    plt.subplot(len(numerical_cols)//3 + 1, 3, idx + 1)\n",
        "    sns.histplot(data[col].dropna(), kde=True, bins=30, color='skyblue')\n",
        "    plt.title(f'Histogram of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boxplots for numerical columns to detect outliers."
      ],
      "metadata": {
        "id": "58Ypd69EKzYW"
      },
      "id": "58Ypd69EKzYW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07d7cc61-fabc-4470-8afb-e9af79b5ca96",
      "metadata": {
        "id": "07d7cc61-fabc-4470-8afb-e9af79b5ca96"
      },
      "outputs": [],
      "source": [
        "# Plot Boxplots\n",
        "plt.figure(figsize=(15, 10))\n",
        "for idx, col in enumerate(numerical_cols):\n",
        "    plt.subplot(len(numerical_cols)//3 + 1, 3, idx + 1)\n",
        "    sns.boxplot(y=data[col], color='lightgreen')\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "    plt.ylabel(col)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation Heatmap to display correlations between numerical columns to identify relationships."
      ],
      "metadata": {
        "id": "EWb5UzGvK7L3"
      },
      "id": "EWb5UzGvK7L3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed1ed16d-1962-470f-ad14-0b22bfad14cd",
      "metadata": {
        "id": "ed1ed16d-1962-470f-ad14-0b22bfad14cd"
      },
      "outputs": [],
      "source": [
        "## Correlation heatmap\n",
        "plt.figure(figsize=(18, 16))\n",
        "corr_matrix = data.drop(columns=['Subject ID', 'Activity_Label'], errors='ignore').corr(method='spearman')\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5, fmt='.2f')\n",
        "plt.title('Correlation Matrix Heatmap', fontsize=18)\n",
        "plt.xticks(fontsize=12, rotation=45, ha='right')\n",
        "plt.yticks(fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identifying and Handling Missing values"
      ],
      "metadata": {
        "id": "XV-jd1c7LGq0"
      },
      "id": "XV-jd1c7LGq0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing Value Identification"
      ],
      "metadata": {
        "id": "hgbuHi0bLKsa"
      },
      "id": "hgbuHi0bLKsa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f16bdf-d758-4735-9b9b-53dac38add18",
      "metadata": {
        "id": "d9f16bdf-d758-4735-9b9b-53dac38add18"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(data.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing Value Visualizations using missingno to visualize missing data patterns"
      ],
      "metadata": {
        "id": "L3x2nVLOLPyI"
      },
      "id": "L3x2nVLOLPyI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "514be93e-e2e4-4e6a-a218-b07846932129",
      "metadata": {
        "id": "514be93e-e2e4-4e6a-a218-b07846932129"
      },
      "outputs": [],
      "source": [
        "# Visualizing missing values using missingno\n",
        "import missingno as msno\n",
        "\n",
        "# Bar plot to visualize the count of non-missing data for each column\n",
        "msno.bar(data, color='dodgerblue')\n",
        "plt.title('Missing Values Bar Plot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8d00a0b-9b2e-4fb9-9517-0d3cb957b90a",
      "metadata": {
        "id": "f8d00a0b-9b2e-4fb9-9517-0d3cb957b90a"
      },
      "outputs": [],
      "source": [
        "# Matrix plot to visualize the distribution of missing data\n",
        "msno.matrix(data.drop(columns=['Subject ID', 'Activity_Label'], errors='ignore'), color=(0.3, 0.4, 0.7))\n",
        "plt.title('Missing Values Matrix Plot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e58fcd4e-12a6-44d1-991f-bfc26a7254a4",
      "metadata": {
        "id": "e58fcd4e-12a6-44d1-991f-bfc26a7254a4"
      },
      "outputs": [],
      "source": [
        "# Heatmap to visualize correlations between missing values in different columns\n",
        "plt.figure(figsize=(18, 16))\n",
        "msno.heatmap(data.drop(columns=['Subject ID', 'Activity_Label'], errors='ignore'), cmap='viridis')\n",
        "plt.title('Missing Values Correlation Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activity Label Distribution\n",
        "for identifying the class imbalances affecting the final analysis"
      ],
      "metadata": {
        "id": "rS38jfAsLdd2"
      },
      "id": "rS38jfAsLdd2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d401167a-7d70-4a5f-9695-d32b414a8451",
      "metadata": {
        "id": "d401167a-7d70-4a5f-9695-d32b414a8451"
      },
      "outputs": [],
      "source": [
        "# Plot the number of samples per each activity label\n",
        "activity_counts = data['Activity_Label'].value_counts()\n",
        "print(\"Number of samples per activity label:\")\n",
        "print(activity_counts)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='Activity_Label', data=data, palette='viridis')\n",
        "plt.title('Number of Samples per Activity Label')\n",
        "plt.xlabel('Activity Label')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction\n",
        "Computing Window Features"
      ],
      "metadata": {
        "id": "h8PdSH66LxyM"
      },
      "id": "h8PdSH66LxyM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2391c5d-1515-4129-b5c4-3727a1627913",
      "metadata": {
        "id": "b2391c5d-1515-4129-b5c4-3727a1627913"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Create a new dataset excluding the Subject ID column\n",
        "data_clean = data.drop(columns=['Subject ID'])\n",
        "\n",
        "# Function to compute window features\n",
        "def compute_window_features(df, window_size=50):\n",
        "    rms_time_series = []\n",
        "    svm_accel_leg = []\n",
        "    svm_gyro_leg = []\n",
        "    svm_accel_hand = []\n",
        "    svm_gyro_hand = []\n",
        "    svm_accel_chest = []\n",
        "    dsvm_accel_leg = []\n",
        "    dsvm_gyro_leg = []\n",
        "    dsvm_accel_hand = []\n",
        "    dsvm_gyro_hand = []\n",
        "    dsvm_accel_chest = []\n",
        "    mean_sample_v = []\n",
        "    labels = []\n",
        "\n",
        "    num_windows = int(np.ceil(len(df) / window_size))\n",
        "\n",
        "    prev_svm_accel_leg = 0\n",
        "    prev_svm_gyro_leg = 0\n",
        "    prev_svm_accel_hand = 0\n",
        "    prev_svm_gyro_hand = 0\n",
        "    prev_svm_accel_chest = 0\n",
        "\n",
        "    for i in range(num_windows):\n",
        "        start = i * window_size\n",
        "        end = start + window_size\n",
        "        window = df.iloc[start:end]\n",
        "\n",
        "        # Compute RMS for time series (Timestamp)\n",
        "        if 'Timestamp (microseconds)' in window.columns and not window['Timestamp (microseconds)'].empty:\n",
        "            rms = np.sqrt(np.mean(np.square(window['Timestamp (microseconds)'])))\n",
        "        else:\n",
        "            rms = np.nan\n",
        "        rms_time_series.append(rms)\n",
        "\n",
        "        # Compute Signal Vector Magnitude (SVM) for accelerometer on leg\n",
        "        leg_accel_cols = ['Accel X (g)_leg', 'Accel Y (g)_leg', 'Accel Z (g)_leg']\n",
        "        if all(col in window.columns for col in leg_accel_cols) and not window[leg_accel_cols].empty:\n",
        "            accel_svm_leg = np.sqrt(\n",
        "                window['Accel X (g)_leg']**2 +\n",
        "                window['Accel Y (g)_leg']**2 +\n",
        "                window['Accel Z (g)_leg']**2\n",
        "            )\n",
        "            avg_accel_svm_leg = accel_svm_leg.mean()\n",
        "        else:\n",
        "            avg_accel_svm_leg = np.nan\n",
        "        svm_accel_leg.append(avg_accel_svm_leg)\n",
        "        dsvm_accel_leg.append(avg_accel_svm_leg - prev_svm_accel_leg)\n",
        "        prev_svm_accel_leg = avg_accel_svm_leg\n",
        "\n",
        "        # Compute Signal Vector Magnitude (SVM) for gyroscope on leg\n",
        "        leg_gyro_cols = ['Gyro X (°/s)_leg', 'Gyro Y (°/s)_leg', 'Gyro Z (°/s)_leg']\n",
        "        if all(col in window.columns for col in leg_gyro_cols) and not window[leg_gyro_cols].empty:\n",
        "            gyro_svm_leg = np.sqrt(\n",
        "                window['Gyro X (°/s)_leg']**2 +\n",
        "                window['Gyro Y (°/s)_leg']**2 +\n",
        "                window['Gyro Z (°/s)_leg']**2\n",
        "            )\n",
        "            avg_gyro_svm_leg = gyro_svm_leg.mean()\n",
        "        else:\n",
        "            avg_gyro_svm_leg = np.nan\n",
        "        svm_gyro_leg.append(avg_gyro_svm_leg)\n",
        "        dsvm_gyro_leg.append(avg_gyro_svm_leg - prev_svm_gyro_leg)\n",
        "        prev_svm_gyro_leg = avg_gyro_svm_leg\n",
        "\n",
        "        # Compute Signal Vector Magnitude (SVM) for accelerometer on hand\n",
        "        hand_accel_cols = ['Accel X (g)_hand', 'Accel Y (g)_hand', 'Accel Z (g)_hand']\n",
        "        if all(col in window.columns for col in hand_accel_cols) and not window[hand_accel_cols].empty:\n",
        "            accel_svm_hand = np.sqrt(\n",
        "                window['Accel X (g)_hand']**2 +\n",
        "                window['Accel Y (g)_hand']**2 +\n",
        "                window['Accel Z (g)_hand']**2\n",
        "            )\n",
        "            avg_accel_svm_hand = accel_svm_hand.mean()\n",
        "        else:\n",
        "            avg_accel_svm_hand = np.nan\n",
        "        svm_accel_hand.append(avg_accel_svm_hand)\n",
        "        dsvm_accel_hand.append(avg_accel_svm_hand - prev_svm_accel_hand)\n",
        "        prev_svm_accel_hand = avg_accel_svm_hand\n",
        "\n",
        "        # Compute Signal Vector Magnitude (SVM) for gyroscope on hand\n",
        "        hand_gyro_cols = ['Gyro X (°/s)_hand', 'Gyro Y (°/s)_hand', 'Gyro Z (°/s)_hand']\n",
        "        if all(col in window.columns for col in hand_gyro_cols) and not window[hand_gyro_cols].empty:\n",
        "            gyro_svm_hand = np.sqrt(\n",
        "                window['Gyro X (°/s)_hand']**2 +\n",
        "                window['Gyro Y (°/s)_hand']**2 +\n",
        "                window['Gyro Z (°/s)_hand']**2\n",
        "            )\n",
        "            avg_gyro_svm_hand = gyro_svm_hand.mean()\n",
        "        else:\n",
        "            avg_gyro_svm_hand = np.nan\n",
        "        svm_gyro_hand.append(avg_gyro_svm_hand)\n",
        "        dsvm_gyro_hand.append(avg_gyro_svm_hand - prev_svm_gyro_hand)\n",
        "        prev_svm_gyro_hand = avg_gyro_svm_hand\n",
        "\n",
        "        # Compute Signal Vector Magnitude (SVM) for accelerometer on chest\n",
        "        chest_accel_cols = ['Accel X (g)_chest', 'Accel Y (g)_chest', 'Accel Z (g)_chest']\n",
        "        if all(col in window.columns for col in chest_accel_cols) and not window[chest_accel_cols].empty:\n",
        "            accel_svm_chest = np.sqrt(\n",
        "                window['Accel X (g)_chest']**2 +\n",
        "                window['Accel Y (g)_chest']**2 +\n",
        "                window['Accel Z (g)_chest']**2\n",
        "            )\n",
        "            avg_accel_svm_chest = accel_svm_chest.mean()\n",
        "        else:\n",
        "            avg_accel_svm_chest = np.nan\n",
        "        svm_accel_chest.append(avg_accel_svm_chest)\n",
        "        dsvm_accel_chest.append(avg_accel_svm_chest - prev_svm_accel_chest)\n",
        "        prev_svm_accel_chest = avg_accel_svm_chest\n",
        "\n",
        "        # Compute mean for Sample (V) column\n",
        "        if 'Sample (V)' in window.columns and not window['Sample (V)'].empty:\n",
        "            mean_v = window['Sample (V)'].mean()\n",
        "        else:\n",
        "            mean_v = np.nan\n",
        "        mean_sample_v.append(mean_v)\n",
        "\n",
        "        # Assign the most frequent label in the window\n",
        "        if 'Activity_Label' in window.columns and not window['Activity_Label'].empty:\n",
        "            most_common_label = Counter(window['Activity_Label']).most_common(1)[0][0]\n",
        "        else:\n",
        "            most_common_label = np.nan\n",
        "        labels.append(most_common_label)\n",
        "\n",
        "    # Create a new DataFrame with the computed features\n",
        "    features_df = pd.DataFrame({\n",
        "        'rms_time_series': rms_time_series,\n",
        "        'svm_accel_leg': svm_accel_leg,\n",
        "        'svm_gyro_leg': svm_gyro_leg,\n",
        "        'svm_accel_hand': svm_accel_hand,\n",
        "        'svm_gyro_hand': svm_gyro_hand,\n",
        "        'svm_accel_chest': svm_accel_chest,\n",
        "        'dsvm_accel_leg': dsvm_accel_leg,\n",
        "        'dsvm_gyro_leg': dsvm_gyro_leg,\n",
        "        'dsvm_accel_hand': dsvm_accel_hand,\n",
        "        'dsvm_gyro_hand': dsvm_gyro_hand,\n",
        "        'dsvm_accel_chest': dsvm_accel_chest,\n",
        "        'mean_sample_v': mean_sample_v,\n",
        "        'label': labels\n",
        "    })\n",
        "\n",
        "    return features_df\n",
        "\n",
        "# Compute the windowed features\n",
        "windowed_features = compute_window_features(data_clean, window_size=50)\n",
        "\n",
        "# Display the first few rows of the computed features\n",
        "print(windowed_features.head())\n",
        "\n",
        "# Export the windowed features to a CSV file\n",
        "windowed_features.to_csv('windowed_features.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling\n",
        "Standardizes the feature values (mean=0, variance=1) for PCA."
      ],
      "metadata": {
        "id": "DhjAZCNPL6B5"
      },
      "id": "DhjAZCNPL6B5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b02e76c4-a1e2-4302-9763-0ce2ca671020",
      "metadata": {
        "id": "b02e76c4-a1e2-4302-9763-0ce2ca671020"
      },
      "outputs": [],
      "source": [
        "# Standardize the data using StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_to_scale = windowed_features.drop(columns=['label'])\n",
        "scaled_features = scaler.fit_transform(features_to_scale)\n",
        "scaled_data = pd.DataFrame(scaled_features, columns=features_to_scale.columns)\n",
        "scaled_data['label'] = windowed_features['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "861b9723-3850-45e8-ae92-00aeee16a608",
      "metadata": {
        "id": "861b9723-3850-45e8-ae92-00aeee16a608",
        "outputId": "7867e684-0a10-4905-e9e9-30ac0516a986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   rms_time_series  svm_accel_leg  svm_gyro_leg  svm_accel_hand  \\\n",
            "0        -1.533833      -0.944386     -1.227765       -0.807131   \n",
            "1        -1.533833      -0.805128     -0.440458       -0.766750   \n",
            "2        -1.533832      -0.635125     -0.241271       -1.041994   \n",
            "3        -1.533831      -0.258103      0.472492       -0.504605   \n",
            "4        -1.533831      -0.626187      0.619819       -0.803859   \n",
            "\n",
            "   svm_gyro_hand  svm_accel_chest  dsvm_accel_leg  dsvm_gyro_leg  \\\n",
            "0      -1.693882        -0.606847        4.048581       0.108165   \n",
            "1      -1.500055        -0.544632        0.273319       1.835933   \n",
            "2      -0.890502        -1.033045        0.333973       0.464430   \n",
            "3      -0.494512        -0.169118        0.742384       1.664427   \n",
            "4      -0.206176        -0.631569       -0.727578       0.343494   \n",
            "\n",
            "   dsvm_accel_hand  dsvm_gyro_hand  dsvm_accel_chest  mean_sample_v   label  \n",
            "0         4.704716        0.325376          7.098262      -0.373538  stairs  \n",
            "1         0.059058        0.228651          0.068390      -0.406575  stairs  \n",
            "2        -0.415289        0.719782         -0.558829      -0.424849  stairs  \n",
            "3         0.806000        0.467482          0.981616      -0.439406  stairs  \n",
            "4        -0.451373        0.340302         -0.529255      -0.470326  stairs  \n"
          ]
        }
      ],
      "source": [
        "# Display the first few rows of the scaled data\n",
        "print(scaled_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA (Principal Component Analysis)\n",
        "Reduces data dimensionality while retaining 90% of the variance. Outputs the number of components selected."
      ],
      "metadata": {
        "id": "y74J1G88MCOG"
      },
      "id": "y74J1G88MCOG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d2fd7e-ef91-421b-a82b-88e3ddb64190",
      "metadata": {
        "id": "16d2fd7e-ef91-421b-a82b-88e3ddb64190"
      },
      "outputs": [],
      "source": [
        "# Apply PCA on the scaled data\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "scaled_columns = scaled_data.drop(columns=['label'])\n",
        "pca = PCA()\n",
        "pca.fit(scaled_columns)\n",
        "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "n_components = np.argmax(cumulative_variance >= 0.90) + 1\n",
        "pca = PCA(n_components=n_components)\n",
        "reduced_features = pca.fit_transform(scaled_columns)\n",
        "print(f'PCA completed with {n_components} components.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scree Plot which Visualizes the explained variance by each PCA component to aid in selecting the optimal number"
      ],
      "metadata": {
        "id": "AQdrInsXMLDt"
      },
      "id": "AQdrInsXMLDt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61142cdd-85d8-44bb-859a-9d5089f917c0",
      "metadata": {
        "id": "61142cdd-85d8-44bb-859a-9d5089f917c0"
      },
      "outputs": [],
      "source": [
        "# Plotting the scree plot for PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
        "plt.axhline(y=0.90, color='r', linestyle='-')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('Scree Plot')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}